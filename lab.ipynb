{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "SOURCE = \"H:\\My Drive\\centroset\\set30.5\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "abm = \"H:\\\\My Drive\\\\anbev-model.keras\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import glob, random, os\n",
        "import pandas as pd\n",
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LQ_HjZkYp_5r"
      },
      "source": [
        "## generate data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z77xjcEwqtT8"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "MAXSHAPE = 30\n",
        "def fill40(arr: np.array):\n",
        "    padded = np.zeros((MAXSHAPE, MAXSHAPE), dtype=arr.dtype)\n",
        "    padded[:arr.shape[0], :arr.shape[1]] = arr[:, :MAXSHAPE]\n",
        "    return padded"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "jFRYttNAqDEw"
      },
      "outputs": [],
      "source": [
        "file_list = glob.glob(SOURCE+'\\*.csv')\n",
        "random.shuffle(file_list)\n",
        "X = []\n",
        "for csv in file_list:\n",
        "    print(f\"loading {csv}\")\n",
        "    df = pd.read_csv(csv, index_col=\"Unnamed: 0\")\n",
        "    X.append(fill40(df.values))\n",
        "\n",
        "y = [0 if f.startswith(\"normal\") else 1 for f in map(os.path.basename, file_list)]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-7kl4c1Ns8uZ"
      },
      "outputs": [],
      "source": [
        "X_train = np.array(X[:40])\n",
        "y_train = np.array(y[:40])\n",
        "X_val = np.array(X[40:])\n",
        "y_val = np.array(y[40:])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5oqBkNBJmtUv"
      },
      "source": [
        "## Building the Model from Scratch\n",
        "\n",
        "But before we continue, let's start defining the model:\n",
        "\n",
        "Step 1 will be to import tensorflow."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "qvfZg3LQbD-5"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "#from itertools import cycle\n",
        "\n",
        "#from sklearn import svm, datasets\n",
        "# from sklearn.metrics import roc_curve, auc\n",
        "#from sklearn.model_selection import train_test_split\n",
        "#from sklearn.preprocessing import label_binarize\n",
        "#from sklearn.multiclass import OneVsRestClassifier\n",
        "#from scipy import interp\n",
        "#from sklearn.metrics import roc_auc_score"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "PixZ2s5QbYQ3"
      },
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([tf.keras.layers.Flatten(input_shape = (30, 30)),\n",
        "                                    tf.keras.layers.Dense(10, activation=tf.nn.relu),\n",
        "                                    tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(32, (3, 3), activation=tf.nn.relu, input_shape=(30, 30)),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(64, (3, 3), activation=tf.nn.relu),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Conv2D(128, (3, 3), activation=tf.nn.relu),\n",
        "    tf.keras.layers.MaxPooling2D((2, 2)),\n",
        "    tf.keras.layers.Flatten(input_shape = (30, 30)),\n",
        "    tf.keras.layers.Dense(10, activation=tf.nn.relu),\n",
        "    tf.keras.layers.Dense(1, activation=tf.nn.sigmoid)\n",
        "    ])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s9EaFDP5srBa"
      },
      "source": [
        "The model.summary() method call prints a summary of the NN"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7ZKj8392nbgP",
        "outputId": "49715ad0-3fb6-4784-8575-7169ac20a9db"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten (Flatten)           (None, 900)               0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 10)                9010      \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 11        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 9021 (35.24 KB)\n",
            "Trainable params: 9021 (35.24 KB)\n",
            "Non-trainable params: 0 (0.00 Byte)\n",
            "_________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "model.summary()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DmtkTn06pKxF"
      },
      "source": [
        "The \"output shape\" column shows the transformation of the dimensions of each layer as a result of the convolution and max pooling - convolution will reduce the layer size by a bit due to padding, and max pooling will halve the output size."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PEkKSpZlvJXA"
      },
      "source": [
        "Next, we'll configure the specifications for model training. We will train our model with the `binary_crossentropy` loss. We will use the `Adam` optimizer. [Adam](https://wikipedia.org/wiki/Stochastic_gradient_descent#Adam) is a sensible optimization algorithm because it automates learning-rate tuning for us (alternatively, we could also use [RMSProp](https://wikipedia.org/wiki/Stochastic_gradient_descent#RMSProp) or [Adagrad](https://developers.google.com/machine-learning/glossary/#AdaGrad) for similar results). We will add accuracy to `metrics` so that the model will monitor accuracy during training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8DHWhFP_uhq3"
      },
      "outputs": [],
      "source": [
        "model.compile(optimizer = tf.optimizers.Adam(),\n",
        "              loss = 'binary_crossentropy',\n",
        "              metrics=['accuracy'])"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mu3Jdwkjwax4"
      },
      "source": [
        "### Training\n",
        "Let's train for 15 epochs.\n",
        "\n",
        "Note that steps_per_epoch was set along with batch_size in ImageDataGenerator so that steps_per_epoch * batch_size = total # of images. For example, for training, 8 * 120 = 960, just under our total of 999 images.\n",
        "\n",
        "Notice that as we train, our validation accuracy never exceeds training accuracy, which is a good thing. Our model won't work better on unseen images than seen images."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fb1_lgobv81m",
        "outputId": "19f2f463-058a-44f4-b9e1-4ce777a0554c"
      },
      "outputs": [],
      "source": [
        "# history = model.fit(\n",
        "#       train_generator,\n",
        "#       steps_per_epoch=8,\n",
        "#       epochs=15,\n",
        "#       verbose=1,\n",
        "#       validation_data = validation_generator,\n",
        "#       validation_steps=8)\n",
        "\n",
        "history = model.fit(x=X_train,\n",
        "      y=y_train,\n",
        "      steps_per_epoch=4,\n",
        "      batch_size=15,\n",
        "      epochs=5,\n",
        "      verbose=1,\n",
        "      validation_data=(X_val, y_val),\n",
        "      shuffle=True\n",
        "      # validation_data = validation_generator,\n",
        "      )"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "model.save('model.keras')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uj5qSfeR1sQ-"
      },
      "source": [
        "## Accuracy, ROC Curve, and AUC"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rRjMyh-68IOB"
      },
      "source": [
        "Let's evaluate the accuracy of our model:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eyA2zQcVKnZE",
        "outputId": "01e6985b-93f8-4c4a-ff3f-f5af5e4ded3a"
      },
      "outputs": [],
      "source": [
        "model.evaluate(X_val, y_val, verbose=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27R_di_J9mA9"
      },
      "source": [
        "Now, let's calculate our ROC curve and plot it.\n",
        "\n",
        "First, let's make predictions on our validation set. When using generators to make predictions, we must first turn off shuffle (as we did when we created validation_generator) and reset the generator:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# load model.keras\n",
        "model = tf.keras.models.load_model('model.keras')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "Kd5fpS-isues",
        "outputId": "ef1a4fd1-597a-4d85-db44-9192be71e449"
      },
      "outputs": [],
      "source": [
        "preds = model.predict(X_val,\n",
        "                      verbose=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h1OnxlGMuVfY",
        "outputId": "60e8a5ac-f08c-40ea-b243-eae415714783"
      },
      "outputs": [],
      "source": [
        "np.hstack(preds)[6]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# filter np array that > 0\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4vmQFPebvDJW",
        "outputId": "d0e4b1ee-39a1-453c-f70b-b22ed7f46b5f"
      },
      "outputs": [],
      "source": [
        "y_val"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "i = random.randint(0, len(X))\n",
        "pred = model.predict(np.array([X[i]]))\n",
        "pred = pred.round().astype(int)[0,0]\n",
        "print(f\"index: {i} pred: {pred}, label: {y[i]}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G0WNZ8b6-Aq9"
      },
      "source": [
        "To create the ROC curve and AUC, we'll need to compute the false-positive rate and the true-positive rate:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oQ1J0M3qVTO8"
      },
      "outputs": [],
      "source": [
        "fpr, tpr, _ = roc_curve(y_val, preds)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IQ-bqubEWDF5"
      },
      "outputs": [],
      "source": [
        "roc_auc = auc(fpr, tpr)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "id": "F8cJa7m0WJyy",
        "outputId": "8be35da9-61dd-40e0-c85d-e7faf74863f8"
      },
      "outputs": [],
      "source": [
        "plt.figure()\n",
        "lw = 2\n",
        "plt.plot(fpr, tpr, color='darkorange',\n",
        "         lw=lw, label='ROC curve (area = %0.2f)' % roc_auc)\n",
        "plt.plot([0, 1], [0, 1], color='navy', lw=lw, linestyle='--')\n",
        "plt.xlim([0.0, 1.0])\n",
        "plt.ylim([0.0, 1.05])\n",
        "plt.xlabel('False Positive Rate')\n",
        "plt.ylabel('True Positive Rate')\n",
        "plt.title('Receiver Operating Characteristic')\n",
        "plt.legend(loc=\"lower right\")\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Rx9o0PJR-SEm"
      },
      "source": [
        "The ROC curve is a probability curve plotting the true-positive rate (TPR) against the false-positive rate (FPR). In this curve, the diagonal line is the curve for random guessing, e.g. coin flipping, so the ROC curve above shows that our model does better than chance at classifying between dandelions and grass. Not bad!\n",
        "\n",
        "Similarly, the AUC (area under curve), as shown in the legend above, measures how much our model is capable of distinguishing between our two classes, dandelions and grass. The higher the AUC, the better our model is at classification. It is also used to compare different models, which I will do in future tutorials when I present how to build an image classifier using Convolutional Neural Networks and transfer learning with ResNet!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "o6vSHzPR2ghH"
      },
      "source": [
        "## Making Predictions\n",
        "\n",
        "Now, let's use the model to make predictions! Upload an image to see if it's a dandelion or grass."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "245MBDnUuP-G"
      },
      "outputs": [],
      "source": [
        "model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 413
        },
        "id": "DoWp43WxJDNT",
        "outputId": "3b4de767-2328-449f-d408-186fa78f7533"
      },
      "outputs": [],
      "source": [
        "%matplotlib inline\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from google.colab import files\n",
        "from keras.preprocessing import image\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "\n",
        "  # predicting images\n",
        "  path = '/content/' + fn\n",
        "  img = image.load_img(path, target_size=(200, 200))\n",
        "  x = image.img_to_array(img)\n",
        "  plt.imshow(x/255.)\n",
        "  x = np.expand_dims(x, axis=0)\n",
        "  images = np.vstack([x])\n",
        "  classes = model.predict(images, batch_size=10)\n",
        "  print(classes[0])\n",
        "  if classes[0]<0.5:\n",
        "    print(fn + \" is a dandelion\")\n",
        "  else:\n",
        "    print(fn + \" is a grass\")\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j4IBgYCYooGD"
      },
      "source": [
        "## Clean Up\n",
        "Run the following cell to terminate the kernel and free memory resources:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "651IgjLyo-Jx"
      },
      "outputs": [],
      "source": [
        "import os, signal\n",
        "os.kill(os.getpid(), signal.SIGKILL)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "osBKw9vU6rHr"
      },
      "outputs": [],
      "source": [
        "round(0.5)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import IPython\n",
        "display(IPython.display.Javascript('window.location.reload()'))"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.5"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
